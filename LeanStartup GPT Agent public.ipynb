{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serpapi_key = 'SERPAPI_KEY'\n",
    "open_api_key = 'OPEN_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.utilities import WikipediaAPIWrapper \n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the llm model\n",
    "\n",
    "llm = OpenAI(openai_api_key=open_api_key, temperature=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your job-to-be-done and customer to be explored\n",
    "\n",
    "customer_description = 'a family consisting of two adults and two children with average income who are renting anu apartment in a big city'\n",
    "job_to_be_done = 'monitoring and paying energy bills'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt hardest part of job to be done for customer\n",
    "hardest_template = PromptTemplate(\n",
    "    input_variables = ['customer_description','job_to_be_done'], \n",
    "    template='You are {customer_description}. What is the hardest part about {job_to_be_done}?')\n",
    "\n",
    "hardest_chain = LLMChain(llm=llm, prompt=hardest_template, verbose=True, output_key='hardest_part')\n",
    "\n",
    "hardest = hardest_chain.run(customer_description=customer_description, job_to_be_done=job_to_be_done)\n",
    "\n",
    "print(hardest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt value proposition to solve hardest part of job-to-be-done\n",
    "\n",
    "value_proposition_template = PromptTemplate(\n",
    "    input_variables = ['hardest_part'], \n",
    "    template='Create a unique value proposition for a startup that solves the problem of {hardest_part}')\n",
    "\n",
    "value_proposition_chain = LLMChain(llm=llm, prompt=value_proposition_template, verbose=True, output_key='value_proposition')\n",
    "\n",
    "valueproposition = value_proposition_chain.run(hardest_part=hardest)\n",
    "\n",
    "print(valueproposition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt description value proposition canvas\n",
    "\n",
    "canvas_template = PromptTemplate(\n",
    "    input_variables = ['value_proposition'], \n",
    "    template='Provide the value proposition canvas for {value_proposition}. You should describe the following elements: customer jobs, custome pains, customer gains, products and services, pain relievers, gain creators')\n",
    "\n",
    "canvas_chain = LLMChain(llm=llm, prompt=canvas_template, verbose=True, output_key='canvas')\n",
    "\n",
    "canvas = canvas_chain.run(value_proposition=valueproposition)\n",
    "\n",
    "print(canvas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt identification of core competitors for this value proposition\n",
    "\n",
    "competitors_template = PromptTemplate(\n",
    "    input_variables = ['value_proposition'], \n",
    "    template='Find three existing startup companies that have a description that is very similar to the following description: {value_proposition}. For each startup, provide company name, location and website.')\n",
    "\n",
    "competitors_chain = LLMChain(llm=llm, prompt=competitors_template, verbose=True, output_key='competitors')\n",
    "\n",
    "competitors = competitors_chain.run(value_proposition=valueproposition)\n",
    "\n",
    "print(competitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt collecting additional information on competitors via SerpAPI\n",
    "\n",
    "\n",
    "competitorsselect = competitors[5:]\n",
    "\n",
    "# split string based on .\n",
    "\n",
    "competitors_list = competitorsselect.split('\\n')\n",
    "\n",
    "competitors_list\n",
    "\n",
    "# get informatin for competitors\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key = serpapi_key)\n",
    "search_tool = [Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\")]\n",
    "\n",
    "self_ask_with_search = initialize_agent(search_tool, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "\n",
    "descriptionlist = []\n",
    "\n",
    "for i in range(len(competitors_list)):\n",
    "    company = competitors_list[i]\n",
    "    searchstring = \"Provide company information for \" + company + \". Include company description and founders\"\n",
    "    result = self_ask_with_search.run(searchstring)\n",
    "    descriptionlist.append(result)\n",
    "\n",
    "print(descriptionlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Generation of hypothese for testing value proposition\n",
    "\n",
    "hypotheses_template = PromptTemplate(\n",
    "    input_variables = ['value_proposition', 'canvas'], \n",
    "    template='Generate a list of hypotheses for testing the following value proposition: {value_proposition}. You should rely on information from the value proposition canvas: {canvas}. Include at least 3 hypotheses. Each hypothesis should focus on the feasibility or viability of the business model. Here are some potential topics for hypotheses testing: willingness to pay, preferred distribution model, ultimate customer segmet, etc.')\n",
    "\n",
    "hypotheses_chain = LLMChain(llm=llm, prompt=hypotheses_template, verbose=True, output_key='hypotheses')\n",
    "\n",
    "hypotheses = hypotheses_chain.run(value_proposition=valueproposition, canvas=canvas)\n",
    "\n",
    "print(hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input and output to text file\n",
    "\n",
    "with open('lean startup description.txt', 'w') as f:\n",
    "    f.write('Input job to be done = ' + job_to_be_done + '\\n')\n",
    "    f.write('Input customer description = ' + customer_description + '\\n')\n",
    "    f.write('\\n' + 'GPT output hardest part of job to be done = ' + hardest +  '\\n')\n",
    "    f.write('\\n' + 'GPT output value proposition = ' + valueproposition +  '\\n')\n",
    "    f.write('\\n' + 'GPT output value proposition canvas = ' + canvas +  '\\n')\n",
    "    f.write('\\n' + 'GPT output most similar competitors = ' + competitors +  '\\n')\n",
    "    f.write('\\n' + 'GPT output company description competitor 1 = ' + str(descriptionlist[0]) +  '\\n')\n",
    "    f.write('\\n' + 'GPT output company description competitor 2 = ' + str(descriptionlist[1]) +  '\\n')\n",
    "    f.write('\\n' + 'GPT output company description competitor 3 = ' + str(descriptionlist[2]) +  '\\n')\n",
    "    f.write('\\n' + 'GPT output hypotheses = ' + hypotheses +  '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
